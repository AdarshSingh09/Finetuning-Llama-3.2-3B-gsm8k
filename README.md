# Fine-Tuned LLaMA 3.2 (3B) on GSM8K Using LoRA and Unsloth
## Model: [Llama-3.2-3B-gsm8k](https://huggingface.co/adarsh09singh/Llama-3.2-3B-gsm8k)
## Dataset: [openai/gsm8k](https://huggingface.co/datasets/openai/gsm8k)

- Utilized the quantized 4-bit `unsloth/llama-3.2-3b-bnb-4bit` model for memory-efficient fine-tuning on the GSM8K dataset (grade-school math reasoning).
- Applied LoRA (Low-Rank Adaptation) for parameter-efficient training, reducing computational overhead while maintaining model performance.



